# backend/main.pyï¼ˆå®Œæ•´ä¿®æ”¹ç‰ˆï¼‰
from fastapi import FastAPI, Depends, HTTPException, Request, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
from jose import jwt, JWTError
from passlib.context import CryptContext
from zhipuai import ZhipuAI
import simplejson as json
import random
import jieba
import jieba.analyse
import jieba.posseg as pseg
from collections import Counter
import re
import hashlib
import requests
import time
from search_service import SearchService
search_service = SearchService()

# ä¿®æ”¹æ£€æµ‹é€»è¾‘
def enhanced_detect(content: str, type: str, keywords: list):
    """å¢å¼ºæ£€æµ‹"""
    # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
    if should_search(content, keywords):
        web_results = search_service.search_rumor(content, keywords)
        # æ„å»ºåŒ…å«æœç´¢ç»“æœçš„æç¤ºè¯
        prompt = build_prompt_with_search(content, type, keywords, web_results)
    else:
        prompt = build_prompt(content, type, keywords)
    
    # è°ƒç”¨GLM-4
    return call_glm4(prompt)

def should_search(content: str, keywords: list) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢"""
    # ç®€å•é€»è¾‘ï¼šå†…å®¹è¾ƒé•¿ä¸”æœ‰å…³é”®è¯
    return len(content) > 20 and len(keywords) >= 2

# å¯¼å…¥è‡ªå·±çš„é…ç½®å’Œæ¨¡å‹
import config
from models import Base, SessionLocal, User, ReasoningRecord, LoginLog

# ---------------------- MCP è”ç½‘æœç´¢å®¢æˆ·ç«¯ï¼ˆå†…è”å®ç°ï¼‰ ----------------------
try:
    from duckduckgo_search import DDGS
    DUCKDUCKGO_AVAILABLE = True
except ImportError:
    DUCKDUCKGO_AVAILABLE = False
    print("âš  duckduckgo-search æœªå®‰è£…ï¼Œå¤‡ç”¨æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")

class ZhipuSearchClient:
    """æ™ºè°±è”ç½‘æœç´¢MCPå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://open.bigmodel.cn/api/mcp/web_search_prime/mcp"):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.timeout = 25
    
    def web_search(self, query: str, max_results: int = 3) -> dict:
        """æ‰§è¡Œè”ç½‘æœç´¢"""
        try:
            request_body = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": "webSearchPrime",
                    "arguments": {
                        "query": query,
                        "limit": max_results
                    }
                },
                "id": int(time.time() * 1000)
            }
            
            print(f"ğŸ” MCPæœç´¢: {query}")
            
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=request_body,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                
                if "result" in result:
                    return self._parse_search_results(result["result"], query)
                elif "error" in result:
                    print(f"âŒ MCPé”™è¯¯: {result['error']}")
            else:
                print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
                
        except requests.exceptions.Timeout:
            print("â° MCPæœç´¢è¶…æ—¶")
        except Exception as e:
            print(f"âŒ MCPå¼‚å¸¸: {str(e)}")
        
        return {"results": [], "query": query, "success": False}
    
    def _parse_search_results(self, result_data: dict, query: str) -> dict:
        """è§£ææœç´¢ç»“æœ"""
        try:
            results = []
            
            if isinstance(result_data, dict):
                if "content" in result_data:
                    results.append({
                        "content": result_data["content"],
                        "title": result_data.get("title", query),
                        "source": "MCPæœç´¢"
                    })
                elif "results" in result_data and isinstance(result_data["results"], list):
                    for item in result_data["results"]:
                        if isinstance(item, dict):
                            results.append({
                                "content": item.get("content") or item.get("snippet") or "",
                                "title": item.get("title") or "",
                                "source": item.get("source", "MCPæœç´¢")
                            })
            elif isinstance(result_data, list):
                for item in result_data:
                    if isinstance(item, dict):
                        results.append({
                            "content": item.get("content") or item.get("snippet") or "",
                            "title": item.get("title") or "",
                            "source": item.get("source", "MCPæœç´¢")
                        })
            
            filtered_results = [r for r in results if r.get("content", "").strip()]
            
            return {
                "results": filtered_results[:3],
                "query": query,
                "success": len(filtered_results) > 0
            }
            
        except Exception as e:
            print(f"è§£æå¤±è´¥: {str(e)}")
            return {"results": [], "query": query, "success": False}
    
    def search_for_rumor_verification(self, content: str, keywords: list) -> str:
        """ä¸ºè°£è¨€éªŒè¯è®¾è®¡çš„æœç´¢"""
        search_queries = self._generate_rumor_queries(content, keywords)
        all_results = []
        
        for query in search_queries[:2]:  # æœ€å¤š2ä¸ªæŸ¥è¯¢
            search_result = self.web_search(query, max_results=2)
            
            if search_result.get("success") and search_result["results"]:
                for result in search_result["results"][:2]:
                    summary = self._extract_verification_info(result)
                    if summary:
                        all_results.append(summary)
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        if all_results:
            return "ğŸ“¡ ç½‘ç»œéªŒè¯ä¿¡æ¯ï¼š\n" + "\n".join(all_results[:3])
        return ""
    
    def _generate_rumor_queries(self, content: str, keywords: list) -> list:
        """ç”Ÿæˆè°£è¨€éªŒè¯æŸ¥è¯¢"""
        queries = []
        
        if keywords:
            main_keywords = " ".join(keywords[:2])
            queries.extend([
                f"{main_keywords} è°£è¨€ è¾Ÿè°£",
                f"{main_keywords} äº‹å®æ ¸æŸ¥",
                f"{main_keywords} çœŸç›¸"
            ])
        
        if len(content) < 100:
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
            for sentence in sentences:
                if 10 < len(sentence) < 50:
                    queries.append(f"{sentence} æ˜¯çœŸçš„å—")
        
        content_lower = content.lower()
        if any(word in content_lower for word in ["ç–«æƒ…", "ç–«è‹—", "æ–°å† "]):
            queries.append("ç–«æƒ…è°£è¨€ å®˜æ–¹è¾Ÿè°£")
        if any(word in content_lower for word in ["é£Ÿå“", "åƒ", "å–"]):
            queries.append("é£Ÿå“å®‰å…¨è°£è¨€")
        
        return list(dict.fromkeys(queries))[:3]  # å»é‡å¹¶é™åˆ¶
    
    def _extract_verification_info(self, result: dict) -> str:
        """æå–éªŒè¯ä¿¡æ¯"""
        try:
            content = result.get("content", "").strip()
            title = result.get("title", "").strip()
            
            if not content:
                return ""
            
            content_short = content[:80] + "..." if len(content) > 80 else content
            
            verification_keywords = ["è¾Ÿè°£", "è°£è¨€", "è¯å®", "äº‹å®", "çœŸç›¸"]
            for keyword in verification_keywords:
                if keyword in content:
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
                    for sentence in sentences:
                        if keyword in sentence and len(sentence) > 10:
                            content_short = sentence.strip()[:70]
                            break
                    break
            
            if title:
                return f"â€¢ {title}: {content_short}"
            else:
                return f"â€¢ {content_short}"
                
        except:
            return ""

class FallbackSearch:
    """å¤‡ç”¨æœç´¢å¼•æ“"""
    
    @staticmethod
    def duckduckgo_search(query: str, max_results: int = 2) -> list:
        if not DUCKDUCKGO_AVAILABLE:
            return []
        
        try:
            with DDGS() as ddgs:
                results = []
                for r in ddgs.text(query, max_results=max_results):
                    results.append({
                        "title": r.get("title", ""),
                        "content": r.get("body", ""),
                        "source": "DuckDuckGo"
                    })
                return results
        except:
            return []
    
    @staticmethod
    def search_for_rumor(query: str) -> str:
        results = FallbackSearch.duckduckgo_search(query, max_results=2)
        
        if not results:
            return ""
        
        summaries = []
        for i, result in enumerate(results, 1):
            title = result.get('title', '')[:40]
            content = result.get('content', '')[:60]
            if content:
                summaries.append(f"{i}. {title}: {content}")
        
        if summaries:
            return "ğŸ” å¤‡ç”¨æœç´¢ï¼š\n" + "\n".join(summaries)
        return ""

# ---------------------- åŸºç¡€é…ç½® ----------------------
app = FastAPI(title="è°£è¨€ç”„åˆ«ç³»ç»ŸAPI")

# è·¨åŸŸé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
from models import SessionLocal

# å¯†ç åŠ å¯†å·¥å…·
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# ---------------------- åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯ ----------------------
from zhipuai import ZhipuAI
import config
llm_client = ZhipuAI(
    api_key=config.LLM_CONFIG["api_key"],
    base_url=config.LLM_CONFIG.get("base_url", "https://open.bigmodel.cn/api/coding/paas/v4")
)
# ---------------------- ä½¿ç”¨jiebaæå–å…³é”®å­—çš„å‡½æ•° ----------------------
def extract_keywords_with_jieba(content: str, top_k: int = 8) -> list:
    """
    ä½¿ç”¨jiebaç²¾ç¡®æ¨¡å¼æå–æ–‡æœ¬çš„å…³é”®å­—
    å‚æ•°:
        content: è¾“å…¥æ–‡æœ¬
        top_k: è¿”å›å…³é”®è¯æ•°é‡
    è¿”å›:
        å…³é”®å­—åˆ—è¡¨
    """
    if not content or len(content.strip()) == 0:
        return ["æœªçŸ¥"]
    
    original_content = content
    
    # æ¸…æ´—æ–‡æœ¬
    important_words = {"ä¸", "æ²¡", "æ— ", "å¦", "é", "æœª", "å‹¿", "è«", "ä¼‘", "å¿Œ", "ç¦", "æˆ’", "å°±", "æ‰€ä»¥", "å› æ­¤", "å› è€Œ", "ä»è€Œ"}
    
    placeholder_map = {}
    for i, word in enumerate(important_words):
        placeholder = f"__PLACEHOLDER_{i}__"
        placeholder_map[placeholder] = word
        content = content.replace(word, placeholder)
    
    cleaned_content = re.sub(r'[^\w\s]', '', content)
    
    for placeholder, word in placeholder_map.items():
        cleaned_content = cleaned_content.replace(placeholder, word)
    
    # ä½¿ç”¨ç²¾ç¡®æ¨¡å¼åˆ†è¯
    words = jieba.lcut(cleaned_content, cut_all=False)
    
    # è¿‡æ»¤é€»è¾‘
    base_stop_words = {"çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "éƒ½", "ä¸€", "ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™"}
    
    important_negations = {"ä¸", "æ²¡", "æ— ", "å¦", "é", "æœª", "å‹¿", "è«", "ä¼‘", "å¿Œ", "ç¦", "æˆ’", "ä¸æ˜¯", "ä¸ä¼š", "ä¸èƒ½", "ä¸å¯", "æ²¡æœ‰", "æ— æ³•"}
    important_logicals = {"æ‰€ä»¥", "å› æ­¤", "å› è€Œ", "ä»è€Œ", "å› ä¸º", "ç”±äº", "æ—¢ç„¶", "é‚£ä¹ˆ", "äºæ˜¯", "ç„¶å"}
    
    must_keep_words = important_negations.union(important_logicals)
    
    filtered_words = []
    for word in words:
        if word in must_keep_words:
            filtered_words.append(word)
        elif word in base_stop_words:
            continue
        elif len(word) == 1 and word not in important_negations:
            continue
        else:
            filtered_words.append(word)
    
    # ç»Ÿè®¡è¯é¢‘
    word_freq = Counter(filtered_words)
    
    # è·å–å‰top_kä¸ªé«˜é¢‘è¯
    keywords = [word for word, _ in word_freq.most_common(top_k)]
    
    # å¦‚æœæå–çš„å…³é”®è¯ä¸è¶³ï¼Œä½¿ç”¨å…³é”®çŸ­è¯­æå–
    if len(keywords) < min(5, top_k):
        try:
            tfidf_keywords = jieba.analyse.extract_tags(
                original_content, 
                topK=top_k*2, 
                withWeight=False,
                allowPOS=('n', 'nr', 'ns', 'nt', 'nz', 'v', 'vn', 'd')
            )
            
            for keyword in tfidf_keywords:
                if keyword in must_keep_words and keyword not in keywords:
                    keywords.append(keyword)
        except:
            pass
    
    # ç‰¹åˆ«å¤„ç†å¦å®š+å…³é”®è¯çš„ç»„åˆ
    negation_patterns = [
        r'ä¸\s*([^\s]+)',
        r'æ²¡\s*([^\s]+)',
        r'æ— \s*([^\s]+)',
        r'å¦\s*([^\s]+)',
        r'é\s*([^\s]+)',
        r'ä¸æ˜¯\s*([^\s]+)',
        r'æ²¡æœ‰\s*([^\s]+)',
    ]
    
    for pattern in negation_patterns:
        matches = re.findall(pattern, original_content)
        for match in matches:
            if len(match) > 1:
                negation_word = pattern.split(r'\s*')[0].replace('r', '').replace("'", "")
                combined = negation_word + match
                if combined not in keywords:
                    keywords.append(combined)
    
    # ä½¿ç”¨è¯æ€§æ ‡æ³¨æå–æ›´å¤šä¿¡æ¯
    try:
        word_flags = pseg.lcut(original_content)
        meaningful_words = []
        for word, flag in word_flags:
            if flag.startswith(('n', 'v', 'a')) and len(word) > 1:
                meaningful_words.append(word)
        
        for word in meaningful_words:
            if word not in keywords:
                keywords.append(word)
    except:
        pass
    
    # å»é‡
    unique_keywords = []
    seen = set()
    for word in keywords:
        if word and word not in seen:
            seen.add(word)
            unique_keywords.append(word)
    
    if not unique_keywords:
        unique_keywords = ["ä¿¡æ¯ä¸è¶³"]
    
    return unique_keywords[:top_k]

# ---------------------- å¤§è¯­è¨€æ¨¡å‹æç¤ºè¯æ¨¡æ¿ ----------------------
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è°£è¨€ç”„åˆ«ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜ï¼š

{{
  "reasoning_steps": [
    "ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å’Œåˆ†ææ–‡æœ¬å†…å®¹",
    "ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥äº‹å®å’Œé€»è¾‘ä¸€è‡´æ€§",
    "ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°å¯ä¿¡åº¦å’Œåˆç†æ€§",
    "ç¬¬å››æ­¥ï¼šç»™å‡ºæœ€ç»ˆåˆ¤æ–­ç»“è®º"
  ],
  "is_ai_generated": false,
  "rumor_prob": 0.8500
}}

=== è¾“å…¥ä¿¡æ¯ ===
æ–‡æœ¬å†…å®¹ï¼š{content}
æ–‡æœ¬ç±»å‹ï¼š{type}
å…³é”®è¯ï¼š{keywords}

=== åˆ†æè¦æ±‚ ===
1. è¯·åŸºäºæä¾›çš„æ–‡æœ¬å†…å®¹ï¼ŒæŒ‰ç…§4æ­¥æ¨ç†æµç¨‹è¿›è¡Œåˆ†æ
2. reasoning_stepså¿…é¡»åŒ…å«4ä¸ªæ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤ç”¨ä¸€å¥ç®€æ´æ˜äº†çš„è¯æè¿°
3. is_ai_generatedåˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºAIç”Ÿæˆï¼štrueï¼ˆæ˜¯ï¼‰æˆ–falseï¼ˆå¦ï¼‰
4. rumor_probç»™å‡ºè°£è¨€æ¦‚ç‡ï¼š0-1ä¹‹é—´çš„4ä½å°æ•°ï¼Œ0è¡¨ç¤ºè‚¯å®šæ˜¯è°£è¨€ï¼Œ1è¡¨ç¤ºè‚¯å®šä¸æ˜¯è°£è¨€
5. è¯·ç¡®ä¿åˆ†æå®¢è§‚ã€å‡†ç¡®ï¼ŒåŸºäºäº‹å®å’Œé€»è¾‘

=== è¾“å‡ºæ ¼å¼è¦æ±‚ ===
åªè¿”å›JSONæ ¼å¼çš„è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€æ³¨é‡Šæˆ–æ ¼å¼æ ‡è®°ã€‚
JSONå¿…é¡»åŒ…å«ä¸”ä»…åŒ…å«ä»¥ä¸‹å­—æ®µï¼šreasoning_steps, is_ai_generated, rumor_prob
"""

# å¢å¼ºçš„æç¤ºè¯æ¨¡æ¿ï¼ˆå¸¦è”ç½‘æœç´¢ï¼‰
ENHANCED_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è°£è¨€ç”„åˆ«ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œåˆ†æï¼š

=== å¾…æ£€æµ‹ä¿¡æ¯ ===
æ–‡æœ¬å†…å®¹ï¼š{content}
æ–‡æœ¬ç±»å‹ï¼š{type}
å…³é”®è¯ï¼š{keywords}

{web_context}

=== åˆ†æè¦æ±‚ ===
1. é¦–å…ˆè¯„ä¼°æ–‡æœ¬ä¸­çš„å£°æ˜æ˜¯å¦å¯éªŒè¯
2. å‚è€ƒç½‘ç»œæœç´¢ç»“æœï¼ˆå¦‚æœæä¾›ï¼‰è¿›è¡Œäº‹å®æ ¸æŸ¥
3. åˆ†æé€»è¾‘ä¸€è‡´æ€§å’Œåˆç†æ€§
4. ç»™å‡ºç»¼åˆåˆ¤æ–­

=== è¾“å‡ºæ ¼å¼ ===
ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{
  "reasoning_steps": [
    "ç¬¬ä¸€æ­¥ï¼šåˆ†ææ–‡æœ¬å†…å®¹",
    "ç¬¬äºŒæ­¥ï¼šæ ¸æŸ¥äº‹å®ä¾æ®", 
    "ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°å¯ä¿¡åº¦",
    "ç¬¬å››æ­¥ï¼šç»¼åˆåˆ¤æ–­ç»“è®º"
  ],
  "is_ai_generated": false,
  "rumor_prob": 0.8500,
  "confidence": "é«˜/ä¸­/ä½",
  "verification_suggestions": ["å»ºè®®1", "å»ºè®®2"]
}}

æ³¨æ„ï¼š
1. rumor_prob: è°£è¨€æ¦‚ç‡ï¼Œ0-1ä¹‹é—´ï¼Œä¿ç•™4ä½å°æ•°
2. confidence: åŸºäºä¿¡æ¯å®Œæ•´åº¦çš„ç½®ä¿¡åº¦
3. verification_suggestions: è¿›ä¸€æ­¥éªŒè¯å»ºè®®
"""

# ---------------------- å·¥å…·å‡½æ•° ----------------------
# 1. è·å–æ•°æ®åº“è¿æ¥
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# 2. å¯†ç åŠ å¯†/éªŒè¯
def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(plain_pwd: str, hashed_pwd: str) -> bool:
    return pwd_context.verify(plain_pwd, hashed_pwd)

# 3. ç”Ÿæˆ/éªŒè¯Token
def create_token(user_id: int) -> str:
    expire = datetime.utcnow() + timedelta(minutes=config.ACCESS_TOKEN_EXPIRE_MINUTES)
    token_data = {"sub": str(user_id), "exp": expire}
    return jwt.encode(token_data, config.SECRET_KEY, algorithm=config.ALGORITHM)

def verify_token(token: str) -> int:
    try:
        payload = jwt.decode(token, config.SECRET_KEY, algorithms=[config.ALGORITHM])
        user_id = int(payload.get("sub"))
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ/è¿‡æœŸ")

# 4. è®¡ç®—å†…å®¹å“ˆå¸Œå€¼çš„å‡½æ•°
def calculate_content_hash(content: str) -> str:
    """è®¡ç®—æ–‡æœ¬å†…å®¹çš„MD5å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
    return hashlib.md5(content.encode('utf-8')).hexdigest()

# 5. æ•°æ®åº“å»é‡æŸ¥è¯¢å‡½æ•°
def find_existing_record(db: Session, content_hash: str) -> dict:
    """
    æ ¹æ®å†…å®¹å“ˆå¸Œå€¼åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾ç°æœ‰è®°å½•
    è¿”å›ï¼šå¦‚æœæ‰¾åˆ°è¿”å›è®°å½•æ•°æ®ï¼Œå¦åˆ™è¿”å›None
    """
    existing_record = db.query(ReasoningRecord).filter(
        ReasoningRecord.content_hash == content_hash
    ).first()
    
    if existing_record:
        # æ›´æ–°ä½¿ç”¨æ¬¡æ•°å’Œæœ€åä½¿ç”¨æ—¶é—´
        existing_record.use_count += 1
        existing_record.last_used_time = datetime.now()
        db.commit()
        
        # è§£æå­˜å‚¨çš„JSONæ•°æ®
        try:
            keywords_data = json.loads(existing_record.keywords) if existing_record.keywords else []
        except:
            keywords_data = []
        
        try:
            reasoning_steps_data = json.loads(existing_record.reasoning_steps) if existing_record.reasoning_steps else []
        except:
            reasoning_steps_data = []
        
        return {
            "rumor_prob": round(float(existing_record.rumor_prob), 4),
            "is_ai_generated": existing_record.is_ai_generated,
            "reasoning_steps": reasoning_steps_data,
            "keywords": keywords_data,
            "from_cache": True,
            "use_count": existing_record.use_count,
            "record_id": existing_record.id
        }
    return None

# 6. æ¨¡æ‹Ÿå¤§è¯­è¨€æ¨¡å‹æ£€æµ‹
def fake_llm_detect(content: str, type: str, keywords: list):
    rumor_prob = round(random.uniform(0, 1), 4)
    reasoning_steps = [
        f"è¯†åˆ«å†…å®¹ï¼š{content[:20]}...ï¼ˆç±»å‹ï¼š{type}ï¼‰",
        f"æ£€æŸ¥äº‹å®ï¼š{'ç¬¦åˆå®¢è§‚äº‹å®' if rumor_prob < 0.5 else 'ä¸ç¬¦åˆå®¢è§‚äº‹å®'}",
        f"è¯„ä¼°åˆç†æ€§ï¼š{'éè°£è¨€' if rumor_prob < 0.5 else 'è°£è¨€'}ï¼ŒAIç”Ÿæˆæ¦‚ç‡ï¼š{round(random.uniform(0, 1), 2)}",
        f"å¾—å‡ºç»“è®ºï¼š{'åˆ¤å®šä¸ºéè°£è¨€' if rumor_prob < 0.5 else 'åˆ¤å®šä¸ºè°£è¨€'}"
    ]
    
    return {
        "rumor_prob": rumor_prob,
        "is_ai_generated": random.choice([True, False]),
        "reasoning_steps": reasoning_steps,
        "from_cache": False
    }

# 7. åˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘æœç´¢
def should_enable_web_search(content: str, keywords: list) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè”ç½‘æœç´¢"""
    # æ£€æŸ¥MCPé…ç½®æ˜¯å¦å¯ç”¨
    if not hasattr(config, 'MCP_CONFIG') or not config.MCP_CONFIG.get("enable", True):
        return False
    
    # å¦‚æœå†…å®¹å¤ªçŸ­
    if len(content) < 15:
        return False
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = config.MCP_CONFIG.get("api_key", "")
    if not api_key or api_key == "your_zhipu_api_key":
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯éªŒè¯çš„å£°æ˜
    verification_triggers = [
        "ç ”ç©¶è¡¨æ˜", "æ•°æ®æ˜¾ç¤º", "ä¸“å®¶ç§°", "æœ€æ–°å‘ç°", "å®éªŒè¯æ˜",
        "æ®æŠ¥é“", "å®˜æ–¹å®£å¸ƒ", "ç§‘å­¦ç ”ç©¶", "äº‹å®è¯æ˜", "è°ƒæŸ¥æ˜¾ç¤º",
        "æ®ç»Ÿè®¡", "æ ¹æ®ç ”ç©¶", "ç§‘å­¦è¯æ˜", "ä¸“å®¶å»ºè®®", "åŒ»ç”Ÿæé†’"
    ]
    
    content_lower = content.lower()
    for trigger in verification_triggers:
        if trigger in content_lower:
            return True
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—æˆ–ç™¾åˆ†æ¯”
    if re.search(r'\d+[%ï¼…]|\d+\.\d+', content):
        return True
    
    # åŸºäºå…³é”®è¯åˆ¤æ–­
    search_keywords = {"ç ”ç©¶", "æ•°æ®", "ç»Ÿè®¡", "å®éªŒ", "æœ€æ–°", "ç§‘å­¦", "è¯æ˜", "ä¸“å®¶", "åŒ»ç”Ÿ", "æ•™æˆ"}
    for keyword in keywords:
        if keyword in search_keywords:
            return True
    
    # ç‰¹å®šç±»å‹å†…å®¹
    if any(word in content_lower for word in ["ç–«æƒ…", "ç–«è‹—", "æ–°å† ", "ç—…æ¯’", "éš”ç¦»", "å°åŸ"]):
        return True
    if any(word in content_lower for word in ["é£Ÿå“", "åƒ", "å–", "ä¸­æ¯’", "è‡´ç™Œ", "æœ‰æ¯’"]):
        return True
    if any(word in content_lower for word in ["å¥åº·", "å…»ç”Ÿ", "æ²»ç—…", "ç–—æ•ˆ", "åæ–¹", "ç§˜æ–¹"]):
        return True
    
    return False

# 8. æ‰§è¡Œè”ç½‘æœç´¢
def perform_web_search(content: str, keywords: list) -> str:
    """æ‰§è¡Œè”ç½‘æœç´¢å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
    try:
        api_key = config.MCP_CONFIG.get("api_key", "")
        if not api_key:
            print("âš  MCP APIå¯†é’¥æœªé…ç½®")
            return ""
        
        print("ğŸ” å¼€å§‹è”ç½‘æœç´¢éªŒè¯...")
        search_client = ZhipuSearchClient(api_key)
        
        # æ‰§è¡Œæœç´¢
        search_summary = search_client.search_for_rumor_verification(content, keywords)
        
        if search_summary:
            print("âœ… è”ç½‘æœç´¢å®Œæˆ")
            return search_summary
        elif config.MCP_CONFIG.get("enable_fallback", True) and DUCKDUCKGO_AVAILABLE:
            # å›é€€åˆ°å¤‡ç”¨æœç´¢
            print("âš  MCPæœç´¢æ— ç»“æœï¼Œå°è¯•å¤‡ç”¨æœç´¢...")
            if keywords:
                query = f"{' '.join(keywords[:2])} è¾Ÿè°£ äº‹å®æ ¸æŸ¥"
                return FallbackSearch.search_for_rumor(query)
            
    except Exception as e:
        print(f"âŒ è”ç½‘æœç´¢å¤±è´¥: {str(e)}")
    
    return ""

# 9. å¢å¼ºçš„æ£€æµ‹å‡½æ•°ï¼ˆå¸¦è”ç½‘æœç´¢ï¼‰
def enhanced_real_llm_detect(content: str, type: str, keywords: list):
    """å¢å¼ºçš„æ£€æµ‹å‡½æ•°ï¼ŒåŒ…å«è”ç½‘æœç´¢"""
    try:
        print(f"ğŸ“ è°ƒç”¨GLM-4æ¨¡å‹APIï¼Œå†…å®¹é•¿åº¦: {len(content)}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘æœç´¢
        should_search = should_enable_web_search(content, keywords)
        web_context = ""
        
        # å¦‚æœéœ€è¦æœç´¢ï¼Œæ‰§è¡Œè”ç½‘æœç´¢
        if should_search:
            web_context = perform_web_search(content, keywords)
            if web_context:
                print("ğŸ“¡ ç½‘ç»œéªŒè¯ä¿¡æ¯å·²è·å–")
            else:
                print("â„¹ï¸ æœªè·å–åˆ°æœ‰æ•ˆçš„ç½‘ç»œéªŒè¯ä¿¡æ¯")
        
        # æ„å»ºæç¤ºè¯
        escaped_content = content.replace("{", "{{").replace("}", "}}")
        escaped_type = type.replace("{", "{{").replace("}", "}}")
        escaped_keywords = str(keywords).replace("{", "{{").replace("}", "}}")
        
        # é€‰æ‹©æç¤ºè¯æ¨¡æ¿
        if web_context:
            # ä½¿ç”¨å¢å¼ºæ¨¡æ¿
            web_context_part = f"=== ç½‘ç»œéªŒè¯ä¿¡æ¯ ===\n{web_context}\n"
            prompt_content = ENHANCED_PROMPT_TEMPLATE.format(
                content=escaped_content,
                type=escaped_type,
                keywords=escaped_keywords,
                web_context=web_context_part
            )
        else:
            # ä½¿ç”¨åŸå§‹æ¨¡æ¿
            prompt_content = PROMPT_TEMPLATE.format(
                content=escaped_content,
                type=escaped_type,
                keywords=escaped_keywords
            )
        
        # è°ƒç”¨GLM-4
        response = llm_client.chat.completions.create(
            model=config.LLM_CONFIG["model_name"],
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„è°£è¨€ç”„åˆ«ä¸“å®¶ï¼Œè¯·åŸºäºæ‰€æœ‰å¯ç”¨ä¿¡æ¯è¿›è¡Œå®¢è§‚åˆ†æã€‚"},
                {"role": "user", "content": prompt_content}
            ],
            temperature=config.LLM_CONFIG["temperature"],
            max_tokens=config.LLM_CONFIG["max_tokens"],
            timeout=30
        )
        
        if not response or not response.choices:
            raise Exception("APIè¿”å›ç©ºå“åº”")
        
        result_str = response.choices[0].message.content.strip()
        
        if not result_str or len(result_str) == 0:
            raise Exception("æ¨¡å‹è¿”å›ç©ºå†…å®¹")
        
        # æ¸…ç†å“åº”æ–‡æœ¬
        if result_str.startswith("```json"):
            result_str = result_str.replace("```json", "").replace("```", "").strip()
        elif result_str.startswith("```"):
            result_str = result_str.replace("```", "").strip()
        
        result_str = re.sub(r'<[^>]+>', '', result_str)
        result_str = re.sub(r'^JSON:\s*', '', result_str, flags=re.IGNORECASE)
        result_str = result_str.strip()
        
        # JSONè§£æ
        result = None
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                result = json.loads(result_str)
                break
            except json.JSONDecodeError:
                if attempt < max_attempts - 1:
                    if "'" in result_str:
                        result_str = result_str.replace("'", "\"")
                    result_str = re.sub(r'\s+', ' ', result_str)
                    if not result_str.endswith("}"):
                        result_str += "}"
                    if not result_str.startswith("{"):
                        start_idx = result_str.find("{")
                        if start_idx != -1:
                            result_str = result_str[start_idx:]
                        else:
                            result_str = "{" + result_str
        
        if result is None:
            raise Exception("JSONè§£æå¤±è´¥")
        
        # è¡¥å…¨å­—æ®µ
        required_fields = ["reasoning_steps", "is_ai_generated", "rumor_prob"]
        for field in required_fields:
            if field not in result:
                if field == "reasoning_steps":
                    result[field] = ["è¯†åˆ«å†…å®¹ï¼šä¿¡æ¯ä¸è¶³", "æ£€æŸ¥äº‹å®ï¼šæ— ç›¸å…³ä¾æ®", "è¯„ä¼°åˆç†æ€§ï¼šæ— æ³•åˆ¤æ–­", "å¾—å‡ºç»“è®ºï¼šä¿¡æ¯ä¸è¶³"]
                elif field == "is_ai_generated":
                    result[field] = False
                elif field == "rumor_prob":
                    result[field] = 0.5000
        
        # ç¡®ä¿æ¨ç†æ­¥éª¤æ˜¯4æ­¥
        if "reasoning_steps" in result:
            if not isinstance(result["reasoning_steps"], list):
                result["reasoning_steps"] = ["è¯†åˆ«å†…å®¹ï¼šä¿¡æ¯ä¸è¶³", "æ£€æŸ¥äº‹å®ï¼šæ— ç›¸å…³ä¾æ®", "è¯„ä¼°åˆç†æ€§ï¼šæ— æ³•åˆ¤æ–­", "å¾—å‡ºç»“è®ºï¼šä¿¡æ¯ä¸è¶³"]
            elif len(result["reasoning_steps"]) != 4:
                while len(result["reasoning_steps"]) < 4:
                    result["reasoning_steps"].append("ä¿¡æ¯ä¸è¶³")
                result["reasoning_steps"] = result["reasoning_steps"][:4]
        
        # ç¡®ä¿è°£è¨€æ¦‚ç‡æ ¼å¼æ­£ç¡®
        if "rumor_prob" in result:
            try:
                rumor_prob = float(result["rumor_prob"])
                rumor_prob = max(0.0, min(1.0, rumor_prob))
                result["rumor_prob"] = round(rumor_prob, 4)
            except:
                result["rumor_prob"] = 0.5000
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        result["from_cache"] = False
        result["web_context_used"] = bool(web_context)
        if web_context:
            result["web_search_summary"] = web_context[:200] + "..." if len(web_context) > 200 else web_context
        
        # ç¡®ä¿æœ‰confidenceå­—æ®µ
        if "confidence" not in result:
            result["confidence"] = "ä¸­"
        
        # ç¡®ä¿æœ‰verification_suggestionså­—æ®µ
        if "verification_suggestions" not in result:
            result["verification_suggestions"] = ["å»ºè®®è¿›ä¸€æ­¥æ ¸å®ä¿¡æ¯æ¥æº"]
        
        return result
        
    except Exception as e:
        print(f"âŒ å¢å¼ºæ£€æµ‹å¤±è´¥ï¼š{str(e)}")
        # å›é€€åˆ°åŸå§‹æ£€æµ‹
        return real_llm_detect(content, type, keywords)

# 10. åŸå§‹æ£€æµ‹å‡½æ•°
def real_llm_detect(content: str, type: str, keywords: list):
    """åŸå§‹çš„å¤§è¯­è¨€æ¨¡å‹æ£€æµ‹å‡½æ•°"""
    try:
        print(f"ğŸ“ è°ƒç”¨GLM-4æ¨¡å‹APIï¼ˆåŸå§‹æ¨¡å¼ï¼‰ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
        
        escaped_content = content.replace("{", "{{").replace("}", "}}")
        escaped_type = type.replace("{", "{{").replace("}", "}}")
        escaped_keywords = str(keywords).replace("{", "{{").replace("}", "}}")
        
        prompt_content = PROMPT_TEMPLATE.format(
            content=escaped_content, 
            type=escaped_type,
            keywords=escaped_keywords
        )
        
        try:
            response = llm_client.chat.completions.create(
                model=config.LLM_CONFIG["model_name"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è°£è¨€ç”„åˆ«ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºJSONæ ¼å¼çš„ç»“æœã€‚"},
                    {"role": "user", "content": prompt_content}
                ],
                temperature=config.LLM_CONFIG["temperature"],
                max_tokens=config.LLM_CONFIG["max_tokens"],
                timeout=30
            )
        except Exception as api_error:
            try:
                response = llm_client.chat.completions.create(
                    model=config.LLM_CONFIG["model_name"],
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è°£è¨€ç”„åˆ«ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºJSONæ ¼å¼çš„ç»“æœã€‚"},
                        {"role": "user", "content": prompt_content}
                    ],
                    temperature=config.LLM_CONFIG["temperature"],
                    max_tokens=config.LLM_CONFIG["max_tokens"],
                    timeout=30
                )
            except Exception as retry_error:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(retry_error)}")
        
        if not response or not response.choices:
            raise Exception("APIè¿”å›ç©ºå“åº”")
        
        result_str = response.choices[0].message.content.strip()
        
        if not result_str or len(result_str) == 0:
            raise Exception("æ¨¡å‹è¿”å›ç©ºå†…å®¹")
        
        # æ¸…ç†å“åº”æ–‡æœ¬
        if result_str.startswith("```json"):
            result_str = result_str.replace("```json", "").replace("```", "").strip()
        elif result_str.startswith("```"):
            result_str = result_str.replace("```", "").strip()
        
        result_str = re.sub(r'<[^>]+>', '', result_str)
        result_str = re.sub(r'^JSON:\s*', '', result_str, flags=re.IGNORECASE)
        result_str = result_str.strip()
        
        # JSONè§£æ
        result = None
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                result = json.loads(result_str)
                break
            except json.JSONDecodeError:
                if attempt < max_attempts - 1:
                    if "'" in result_str:
                        result_str = result_str.replace("'", "\"")
                    result_str = re.sub(r'\s+', ' ', result_str)
                    if not result_str.endswith("}"):
                        result_str += "}"
                    if not result_str.startswith("{"):
                        start_idx = result_str.find("{")
                        if start_idx != -1:
                            result_str = result_str[start_idx:]
                        else:
                            result_str = "{" + result_str
        
        if result is None:
            raise Exception("JSONè§£æå¤±è´¥")
        
        # è¡¥å…¨å­—æ®µ
        required_fields = ["reasoning_steps", "is_ai_generated", "rumor_prob"]
        for field in required_fields:
            if field not in result:
                if field == "reasoning_steps":
                    result[field] = ["è¯†åˆ«å†…å®¹ï¼šä¿¡æ¯ä¸è¶³", "æ£€æŸ¥äº‹å®ï¼šæ— ç›¸å…³ä¾æ®", "è¯„ä¼°åˆç†æ€§ï¼šæ— æ³•åˆ¤æ–­", "å¾—å‡ºç»“è®ºï¼šä¿¡æ¯ä¸è¶³"]
                elif field == "is_ai_generated":
                    result[field] = False
                elif field == "rumor_prob":
                    result[field] = 0.5000
        
        # ç¡®ä¿æ¨ç†æ­¥éª¤æ˜¯4æ­¥
        if "reasoning_steps" in result:
            if not isinstance(result["reasoning_steps"], list):
                result["reasoning_steps"] = ["è¯†åˆ«å†…å®¹ï¼šä¿¡æ¯ä¸è¶³", "æ£€æŸ¥äº‹å®ï¼šæ— ç›¸å…³ä¾æ®", "è¯„ä¼°åˆç†æ€§ï¼šæ— æ³•åˆ¤æ–­", "å¾—å‡ºç»“è®ºï¼šä¿¡æ¯ä¸è¶³"]
            elif len(result["reasoning_steps"]) != 4:
                while len(result["reasoning_steps"]) < 4:
                    result["reasoning_steps"].append("ä¿¡æ¯ä¸è¶³")
                result["reasoning_steps"] = result["reasoning_steps"][:4]
        
        # ç¡®ä¿è°£è¨€æ¦‚ç‡æ ¼å¼æ­£ç¡®
        if "rumor_prob" in result:
            try:
                rumor_prob = float(result["rumor_prob"])
                rumor_prob = max(0.0, min(1.0, rumor_prob))
                result["rumor_prob"] = round(rumor_prob, 4)
            except:
                result["rumor_prob"] = 0.5000
        
        result["from_cache"] = False
        result["web_context_used"] = False
        
        return result
    except Exception as e:
        print(f"âŒ GLM-4æ¨¡å‹è°ƒç”¨/è§£æå¤±è´¥ï¼š{str(e)}")
        return {
            "reasoning_steps": ["è¯†åˆ«å†…å®¹ï¼šæ¨¡å‹è°ƒç”¨å¼‚å¸¸", "æ£€æŸ¥äº‹å®ï¼šæ£€æµ‹å¤±è´¥", "è¯„ä¼°åˆç†æ€§ï¼šæ— æ³•åˆ¤æ–­", "å¾—å‡ºç»“è®ºï¼šä¿¡æ¯ä¸è¶³"],
            "is_ai_generated": False,
            "rumor_prob": 0.5000,
            "from_cache": False,
            "web_context_used": False
        }

# ---------------------- æ•°æ®æ¨¡å‹ ----------------------
class RegisterRequest(BaseModel):
    username: str
    password: str
    confirm_password: str

class LoginRequest(BaseModel):
    username: str
    password: str

class DetectRequest(BaseModel):
    content: str
    type: str

# ---------------------- æ ¸å¿ƒæ¥å£ ----------------------
@app.post("/api/register")
def register(request: RegisterRequest, db: Session = Depends(get_db)):
    if not request.username or not request.password or not request.confirm_password:
        raise HTTPException(status_code=400, detail="æ‰€æœ‰å­—æ®µä¸èƒ½ä¸ºç©º")
    
    if len(request.password) < 6 or len(request.password) > 72:
        raise HTTPException(status_code=400, detail="å¯†ç é•¿åº¦éœ€6-72ä½")
    
    if request.password != request.confirm_password:
        raise HTTPException(status_code=400, detail="ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´")
    
    if db.query(User).filter(User.username == request.username).first():
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åå·²å­˜åœ¨")
    
    hashed_pwd = hash_password(request.password[:72])
    new_user = User(
        username=request.username,
        password=hashed_pwd,
        create_time=datetime.now()
    )
    try:
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç”¨æˆ·å¤±è´¥ï¼š{str(e)}")
    
    return {
        "code": 200,
        "msg": "æ³¨å†ŒæˆåŠŸï¼Œè¯·ç™»å½•",
        "data": {
            "user_id": new_user.id,
            "username": new_user.username
        }
    }

@app.post("/api/login")
def login(request: LoginRequest, req: Request, db: Session = Depends(get_db)):
    if not request.username or not request.password:
        raise HTTPException(status_code=400, detail="ç”¨æˆ·å/å¯†ç ä¸èƒ½ä¸ºç©º")
    
    user = db.query(User).filter(User.username == request.username).first()
    if not user:
        raise HTTPException(status_code=401, detail="ç”¨æˆ·åä¸å­˜åœ¨")
    
    if not verify_password(request.password, user.password):
        raise HTTPException(status_code=401, detail="å¯†ç é”™è¯¯")
    
    try:
        login_log = LoginLog(user_id=user.id, ip=req.client.host)
        db.add(login_log)
        db.commit()
    except Exception as e:
        db.rollback()
        print(f"è®°å½•ç™»å½•æ—¥å¿—å¤±è´¥ï¼š{str(e)}")
    
    token = create_token(user.id)
    return {
        "code": 200,
        "msg": "ç™»å½•æˆåŠŸ",
        "data": {
            "token": token,
            "user_id": user.id,
            "username": user.username
        }
    }

# ---------------------- æ£€æµ‹æ¥å£ï¼ˆå¸¦è”ç½‘æœç´¢ï¼‰ ----------------------
@app.post("/api/detect")
def detect(
    request: DetectRequest,
    authorization: str = Header(None),
    db: Session = Depends(get_db)
):
    # 1. éªŒè¯Token
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    token = authorization.split(" ")[1]
    try:
        user_id = verify_token(token)
    except:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ/è¿‡æœŸ")
    
    # 2. æ ¡éªŒæ–‡æœ¬é•¿åº¦
    if len(request.content) < 1 or len(request.content) > 500:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬é•¿åº¦éœ€1-500å­—")
    
    # 3. è®¡ç®—å†…å®¹å“ˆå¸Œå€¼ï¼ˆç”¨äºå»é‡ï¼‰
    content_hash = calculate_content_hash(request.content)
    print(f"ğŸ”‘ å†…å®¹å“ˆå¸Œå€¼: {content_hash}")
    
    # 4. å…ˆæŸ¥è¯¢æ•°æ®åº“æ˜¯å¦æœ‰ç›¸åŒå†…å®¹çš„è®°å½•
    existing_record = find_existing_record(db, content_hash)
    if existing_record:
        print(f"âœ… æ‰¾åˆ°ç¼“å­˜è®°å½•ï¼Œä½¿ç”¨æ¬¡æ•°: {existing_record['use_count']}")
        return {
            "code": 200,
            "msg": "æ£€æµ‹æˆåŠŸï¼ˆæ¥è‡ªç¼“å­˜ï¼‰",
            "data": {
                "rumor_prob": existing_record["rumor_prob"],
                "is_ai_generated": existing_record["is_ai_generated"],
                "reasoning_steps": existing_record["reasoning_steps"],
                "keywords": existing_record["keywords"],
                "record_id": existing_record["record_id"],
                "from_cache": True,
                "use_count": existing_record["use_count"],
                "web_context_used": False
            }
        }
    
    # 5. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™æå–å…³é”®å­—
    keywords = extract_keywords_with_jieba(request.content)
    print(f"ğŸ”‘ æå–çš„å…³é”®å­—: {keywords}")
    print("ğŸ”„ æœªæ‰¾åˆ°ç¼“å­˜è®°å½•ï¼Œè°ƒç”¨å¤§æ¨¡å‹...")
    
    # 6. è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹
    if config.LLM_FAKE:
        print("ğŸ¤– ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        llm_result = fake_llm_detect(request.content, request.type, keywords)
    else:
        print("ğŸš€ ä½¿ç”¨GLM-4çœŸå®APIæ¨¡å¼ï¼ˆå¸¦è”ç½‘æœç´¢ï¼‰")
        llm_result = enhanced_real_llm_detect(request.content, request.type, keywords)
    
    # 7. å­˜å‚¨æ–°çš„æ£€æµ‹è®°å½•åˆ°æ•°æ®åº“
    try:
        record = ReasoningRecord(
            user_id=user_id,
            content=request.content,
            content_hash=content_hash,
            type=request.type,
            rumor_prob=llm_result["rumor_prob"],
            is_ai_generated=llm_result["is_ai_generated"],
            reasoning_steps=json.dumps(llm_result["reasoning_steps"], ensure_ascii=False),
            keywords=json.dumps(keywords, ensure_ascii=False),
            use_count=1,
            create_time=datetime.now(),
            last_used_time=datetime.now()
        )
        db.add(record)
        db.commit()
        db.refresh(record)
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"å­˜å‚¨æ£€æµ‹è®°å½•å¤±è´¥ï¼š{str(e)}")
    
    # 8. è¿”å›ç»“æœç»™å‰ç«¯
    response_data = {
        "rumor_prob": round(llm_result["rumor_prob"], 4),
        "is_ai_generated": llm_result["is_ai_generated"],
        "reasoning_steps": llm_result["reasoning_steps"],
        "keywords": keywords,
        "record_id": record.id,
        "from_cache": False,
        "use_count": 1,
        "web_context_used": llm_result.get("web_context_used", False)
    }
    
    # æ·»åŠ é¢å¤–å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if "confidence" in llm_result:
        response_data["confidence"] = llm_result["confidence"]
    if "verification_suggestions" in llm_result:
        response_data["verification_suggestions"] = llm_result["verification_suggestions"]
    if "web_search_summary" in llm_result:
        response_data["web_search_summary"] = llm_result["web_search_summary"]
    
    return {
        "code": 200,
        "msg": "æ£€æµ‹æˆåŠŸ" + ("ï¼ˆå«è”ç½‘éªŒè¯ï¼‰" if llm_result.get("web_context_used") else "ï¼ˆå®æ—¶åˆ†æï¼‰"),
        "data": response_data
    }

@app.get("/api/history")
def get_history(
    authorization: str = Header(None),
    page: int = 1,
    size: int = 10,
    db: Session = Depends(get_db)
):
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    token = authorization.split(" ")[1]
    try:
        user_id = verify_token(token)
    except:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ/è¿‡æœŸ")
    
    if page < 1:
        page = 1
    if size < 1 or size > 50:
        size = 10
    
    offset = (page - 1) * size
    records = db.query(ReasoningRecord).filter(ReasoningRecord.user_id == user_id).order_by(ReasoningRecord.last_used_time.desc()).offset(offset).limit(size).all()
    
    history_list = []
    for r in records:
        try:
            keywords_data = json.loads(r.keywords) if r.keywords else []
        except:
            keywords_data = []
        
        try:
            reasoning_steps_data = json.loads(r.reasoning_steps) if r.reasoning_steps else []
        except:
            reasoning_steps_data = []
        
        history_list.append({
            "record_id": r.id,
            "content": r.content,
            "content_hash": r.content_hash,
            "type": r.type,
            "rumor_prob": round(float(r.rumor_prob), 4),
            "is_ai_generated": r.is_ai_generated,
            "keywords": keywords_data,
            "reasoning_steps": reasoning_steps_data,
            "use_count": r.use_count,
            "create_time": r.create_time.strftime("%Y-%m-%d %H:%M:%S") if r.create_time else "",
            "last_used_time": r.last_used_time.strftime("%Y-%m-%d %H:%M:%S") if r.last_used_time else ""
        })
    total = db.query(ReasoningRecord).filter(ReasoningRecord.user_id == user_id).count()
    return {
        "code": 200,
        "msg": "æŸ¥è¯¢æˆåŠŸ",
        "data": {
            "total": total,
            "page": page,
            "size": size,
            "list": history_list
        }
    }

# ---------------------- æ–°å¢ï¼šæŸ¥çœ‹é‡å¤å†…å®¹ç»Ÿè®¡æ¥å£ ----------------------
@app.get("/api/duplicate-stats")
def get_duplicate_stats(
    authorization: str = Header(None),
    db: Session = Depends(get_db)
):
    """æŸ¥çœ‹é‡å¤å†…å®¹ç»Ÿè®¡ä¿¡æ¯"""
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    token = authorization.split(" ")[1]
    try:
        user_id = verify_token(token)
    except:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ/è¿‡æœŸ")
    
    # ç»Ÿè®¡ä½¿ç”¨æ¬¡æ•°æœ€å¤šçš„å†…å®¹
    most_used = db.query(ReasoningRecord).filter(
        ReasoningRecord.user_id == user_id
    ).order_by(ReasoningRecord.use_count.desc()).limit(5).all()
    
    most_used_list = []
    for record in most_used:
        most_used_list.append({
            "content": record.content[:50] + "..." if len(record.content) > 50 else record.content,
            "use_count": record.use_count,
            "last_used": record.last_used_time.strftime("%Y-%m-%d %H:%M:%S") if record.last_used_time else ""
        })
    
    # ç»Ÿè®¡ç¼“å­˜å‘½ä¸­ç‡
    total_records = db.query(ReasoningRecord).filter(ReasoningRecord.user_id == user_id).count()
    duplicate_records = db.query(ReasoningRecord).filter(
        ReasoningRecord.user_id == user_id,
        ReasoningRecord.use_count > 1
    ).count()
    
    cache_hit_rate = 0
    if total_records > 0:
        cache_hit_rate = round((duplicate_records / total_records) * 100, 2)
    
    return {
        "code": 200,
        "msg": "ç»Ÿè®¡æˆåŠŸ",
        "data": {
            "total_records": total_records,
            "duplicate_records": duplicate_records,
            "cache_hit_rate": f"{cache_hit_rate}%",
            "most_used_contents": most_used_list
        }
    }

# ---------------------- æ–°å¢ï¼šæ£€æŸ¥è”ç½‘æœç´¢çŠ¶æ€æ¥å£ ----------------------
@app.get("/api/web-search-status")
def get_web_search_status(
    authorization: str = Header(None),
    db: Session = Depends(get_db)
):
    """æ£€æŸ¥è”ç½‘æœç´¢åŠŸèƒ½çŠ¶æ€"""
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    token = authorization.split(" ")[1]
    try:
        user_id = verify_token(token)
    except:
        raise HTTPException(status_code=401, detail="Tokenæ— æ•ˆ/è¿‡æœŸ")
    
    status_info = {
        "mcp_enabled": hasattr(config, 'MCP_CONFIG') and config.MCP_CONFIG.get("enable", True),
        "api_key_configured": False,
        "duckduckgo_available": DUCKDUCKGO_AVAILABLE,
        "fallback_enabled": hasattr(config, 'MCP_CONFIG') and config.MCP_CONFIG.get("enable_fallback", True)
    }
    
    if status_info["mcp_enabled"]:
        api_key = config.MCP_CONFIG.get("api_key", "")
        status_info["api_key_configured"] = bool(api_key and api_key != "your_zhipu_api_key")
        status_info["api_key_masked"] = api_key[:8] + "..." + api_key[-4:] if api_key and len(api_key) > 12 else "æœªé…ç½®"
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    test_result = "æœªæµ‹è¯•"
    if status_info["mcp_enabled"] and status_info["api_key_configured"]:
        try:
            search_client = ZhipuSearchClient(config.MCP_CONFIG["api_key"])
            test_search = search_client.web_search("æµ‹è¯•", max_results=1)
            test_result = "æ­£å¸¸" if test_search.get("success") else f"å¤±è´¥: {test_search.get('error', 'æœªçŸ¥é”™è¯¯')}"
        except Exception as e:
            test_result = f"å¼‚å¸¸: {str(e)}"
    
    status_info["test_result"] = test_result
    
    return {
        "code": 200,
        "msg": "çŠ¶æ€æŸ¥è¯¢æˆåŠŸ",
        "data": status_info
    }

# ---------------------- å¯åŠ¨åç«¯ ----------------------
if __name__ == "__main__":
    try:
        jieba.load_userdict('userdict.txt')
        print("âœ… jiebaåˆ†è¯å™¨åˆå§‹åŒ–æˆåŠŸ - åŠ è½½è‡ªå®šä¹‰è¯å…¸")
    except:
        print("âœ… jiebaåˆ†è¯å™¨åˆå§‹åŒ–æˆåŠŸ - ä½¿ç”¨é»˜è®¤è¯å…¸")
    
    # åˆå§‹åŒ–æ•°æ®åº“å’Œæµ‹è¯•ç”¨æˆ·
    db = SessionLocal()
    try:
        if not db.query(User).filter(User.username == "test").first():
            password = str("123456")[:72]
            test_user = User(username="test", password=hash_password(password))
            db.add(test_user)
            db.commit()
            print("âœ… æµ‹è¯•ç”¨æˆ·åˆ›å»ºæˆåŠŸï¼šç”¨æˆ·åtestï¼Œå¯†ç 123456")
        else:
            print("âœ… æµ‹è¯•ç”¨æˆ·å·²å­˜åœ¨")
            
        # æ£€æŸ¥è”ç½‘æœç´¢é…ç½®
        print("\n=== è”ç½‘æœç´¢åŠŸèƒ½çŠ¶æ€ ===")
        if hasattr(config, 'MCP_CONFIG'):
            print(f"âœ“ MCPé…ç½®å·²åŠ è½½")
            print(f"âœ“ å¯ç”¨çŠ¶æ€: {config.MCP_CONFIG.get('enable', True)}")
            api_key = config.MCP_CONFIG.get('api_key', '')
            if api_key and api_key != "your_zhipu_api_key":
                print(f"âœ“ APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else ''}")
            else:
                print(f"âš  APIå¯†é’¥: æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
            print(f"âœ“ å¤‡ç”¨æœç´¢: {'å¯ç”¨' if DUCKDUCKGO_AVAILABLE else 'ä¸å¯ç”¨'}")
        else:
            print("âš  MCPé…ç½®æœªæ‰¾åˆ°ï¼Œè”ç½‘æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")
        
        print("\n=== æ•°æ®åº“å»é‡åŠŸèƒ½çŠ¶æ€ ===")
        print("âœ“ content_hashå­—æ®µå·²æ·»åŠ ")
        print("âœ“ use_countå­—æ®µå·²æ·»åŠ ")
        print("âœ“ last_used_timeå­—æ®µå·²æ·»åŠ ")
        print("âœ“ å»é‡æŸ¥è¯¢åŠŸèƒ½å·²å¯ç”¨")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        db.rollback()
    finally:
        db.close()
    
    print(f"\n=== è°£è¨€ç”„åˆ«ç³»ç»Ÿåç«¯å¯åŠ¨ ===")
    print(f"ğŸ“± æ¨¡å‹é…ç½®: {config.LLM_CONFIG['model_name']}")
    print(f"ğŸ”— è”ç½‘æœç´¢: {'å·²å¯ç”¨' if hasattr(config, 'MCP_CONFIG') and config.MCP_CONFIG.get('enable', True) else 'æœªå¯ç”¨'}")
    print(f"ğŸ’¾ å»é‡åŠŸèƒ½: å·²å¯ç”¨")
    print(f"ğŸ¤– LLM_FAKEæ¨¡å¼: {config.LLM_FAKE}")
    print(f"ğŸŒ æœåŠ¡åœ°å€: http://localhost:8000")
    print(f"ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
    print(f"ğŸ” è”ç½‘çŠ¶æ€æ£€æŸ¥: http://localhost:8000/api/web-search-status")
    
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)